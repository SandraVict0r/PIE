import os
import pickle
import copy
import numpy as np
from scipy import signal
from utilities.jaad_data import JAAD
from utilities.pie_data import PIE
from utilities.utils import print_msg, exception, assertion
from utilities.utils import print_tracks_stats, print_2msg
from utilities.utils import read_pickle, get_areas


def get_dataset(dataset, data_path=None):
    """
    Returns the dataset object. The assumption is that the path is set up as an environment variable. If not should be
    passed to the function.
    Args:
        dataset: the name of the dataset
        data_path: the path to the data folder. If None, it will read from the environment variable

    Returns:
        Dataset object
    """
    if dataset.lower() == 'jaad':
        jaad_path = data_path or os.environ['JAAD_PATH']
        return JAAD(data_path=jaad_path)
    elif dataset.lower() == 'pie':
        pie_path = data_path or os.environ['PIE_PATH']
        return PIE(data_path=pie_path)
    else:
        raise Exception(f"{dataset.lower()} dataset is not supported")


def get_tracks(data_raw, opts, subset='train'):
    """
    Generates data sequences for training, testing or validation
    Args:
        data_raw: the raw data generated by the dataset API
        opts: options for generating data
        subset: whether it is train, test, or val subset

    Returns:
        A dictionary of data sequences
    """
    print_msg('###### Generating raw data ######')
    time_to_event = opts['time_to_event']
    img_dimension = data_raw["image_dimension"]
    _data = {}
    dtypes = get_data_types(opts)
    if 'vehicle' in dtypes:
        dtypes.update(get_vehicle_dtypes(opts['vehicle_data'], opts))
        dtypes.remove('vehicle')

    for dtype in dtypes:
        if 'grid' in dtype:
            grid_count = add_grid_coordinates(_data, opts['grid_resolution'], img_dimension, data_raw['center'])
        elif dtype == 'intention':
            _data['intention'] = get_intention_labels(data_raw, opts)
        elif dtype == 'speed':
            _data[dtype] = data_raw['obd_speed']
        elif dtype in ['risk_class', 'tte', 'intention']:
            continue
        else:
            dt = dtype.split('norm_')[1] if 'norm' in dtype else dtype
            dt = dtype.split('scaled_')[1] if 'scaled' in dt else dt
            _data[dtype] = data_raw[dt]

    # Extract samples from raw sequences
    if opts['sequence_type'] == 'intention':
        if 'intention' not in _data:
            _data['intention'] = get_intention_labels(data_raw, opts)
        extract_tracks_intent(_data, data_raw['intent_frames_idx'],
                              data_raw['event_frames_idx'],
                              img_dimension, **opts)
    elif isinstance(time_to_event, list) and len(time_to_event) == 2:
        extract_tracks_tte(_data, img_dimension, data_raw['event_frames_idx'], **opts)
    elif (isinstance(time_to_event, list) and len(time_to_event) == 0) or time_to_event is None:
        extract_tracks(_data, img_dimension, **opts)
    else:
        exception(f"Time to event is {time_to_event}. It should be a list of two numbers, an empty list, or None")

    # Add additional data
    apply_filter_vehicle_data(_data, subset, opts)
    add_scaled_coordinates(_data, opts)

    # Normalize the coordinates by subtracting the first frame from the rest
    _get_norm_tracks(_data, opts)
    return _data


def extract_tracks_intent(_data, intent_frames_idx, event_frames_idx,
                          img_dimension, obs_len, pred_len, overlap,
                          num_int_class=3, risk_horizon=90, **kwargs):
    """
    Generates data samples for intention task from the PIE raw data
    Args:
        _data: list of raw data extracted using data object
        intent_frames_idx: the indices of the intention start and end points
        event_frames_idx: the index of crossing event frame
        img_dimension: image dimension
        obs_len: observation length
        pred_len: prediction length
        overlap: percentage of overlap between the sampled tracks
        num_int_class: number of intention classes. This is used to discretize intention probability into classes
        risk_horizon: the risk horizon in terms of the number of frames in the future

    Returns:
        None
    """

    # Sample sequence within a range of TTE values
    print_msg('Generating intent data')
    overlap_stride = obs_len if overlap == 0 else \
        int((1 - overlap) * obs_len)
    overlap_stride = 1 if overlap_stride < 1 else overlap_stride
    sequence_length = obs_len + pred_len
    gen_tte_risk = True
    _adata = {'tte': [], 'risk_class': []}
    for k in _data:
        tracks = []
        samp_excluded = [0] * num_int_class
        for e_idx, seq in enumerate(_data[k]):
            # Exclude samples that have very short sequence
            if intent_frames_idx[e_idx][1] - intent_frames_idx[e_idx][0] < obs_len:
                samp_excluded[_data['intention'][e_idx][0][0]] += 1
                continue
            # Compute the first and last frame indices
            _start = intent_frames_idx[e_idx][0]
            _end = intent_frames_idx[e_idx][1] + 1

            # Sample tracks from the data sequence
            for i in range(_start, _end, overlap_stride):
                _trk = seq[i:i + sequence_length]
                # if track too short (in case of traj prediction or risk assessment), repeat the last entry
                if len(_trk) < sequence_length:
                    num_rep = sequence_length - len(_trk)
                    _trk += _trk[-1:] * num_rep
                tracks.append(_trk)
            # Generate TTE and risk class labels in the first iteration
            if gen_tte_risk:
                _adata['tte'].extend(
                    [[[event_frames_idx[e_idx] - i]] * sequence_length for i in range(_start, _end, overlap_stride)])
                _adata['risk_class'].extend([_data['bbox'][e_idx][i:i + obs_len + risk_horizon][-1] for i in
                                             range(_start, _end, overlap_stride)])
        _data[k] = tracks
        if gen_tte_risk:
            gen_tte_risk = False
    _data.update(_adata)
    convert_risk_classes(_data, img_dimension[0], **kwargs)

    print_msg(f"{samp_excluded} pedestrian instances excluded", 'default')
    print_2msg(f"Total number of samples:", f"{len(_data['bbox'])}")
    cls_count = [0] * num_int_class
    for seq in _data['intention']:
        cls_count[seq[0][0]] += 1
    print_msg('class, count', 'purple')
    print_msg("\t".join([str(i) for i in range(num_int_class)]), 'default')
    print_msg("\t".join([str(i) for i in cls_count]), 'default')


def extract_tracks(_data, img_dimension, obs_len, pred_len, overlap, risk_horizon=90, **kwargs):
    """
    Generates data sequences for behavior prediction with event points
    Args:
        _data: list of raw data points
        img_dimension: image dimension
        obs_len: length of observation
        pred_len: length of prediction
        overlap: percentage of overlap between sampled sequences
        risk_horizon: the risk horizon in terms of the number of frames in the future

    Returns:
        None
    """
    # Sample from entire sequences
    print_msg('Generating data: all')
    sequence_length = obs_len + pred_len
    overlap_stride = obs_len if overlap == 0 else \
        int((1 - overlap) * obs_len)
    overlap_stride = 1 if overlap_stride < 1 else overlap_stride
    for k in _data:
        tracks = []
        for track in _data[k]:
            tracks.extend(
                [track[i:i + sequence_length] for i in range(0, len(track) - sequence_length + 1, overlap_stride)])
        _data[k] = tracks
    _data['risk_class'] = []
    for track in _data['bbox']:
        _data['risk_class'].extend([track[i:i + obs_len + risk_horizon][-1] for i in
                                   range(0, len(track) - sequence_length + 1, overlap_stride)])

    convert_risk_classes(_data, img_dimension[0], **kwargs)


def extract_tracks_tte(_data, img_dimension,
                       event_frames_idx,
                       obs_len, pred_len,
                       time_to_event, overlap,
                       exclude_short_seq=False,
                       risk_horizon=90, **kwargs):
    """
    Generates data samples for behavior prediction with time to event points
    Args:
        _data: list of raw data points
        img_dimension: image dimension
        event_frames_idx: list of indices of crossing events
        obs_len: observation length
        pred_len: prediction length
        time_to_event: time to event period in the form of list of two integers [<val1>, <val2>]
        overlap: percentage of overlap between sampled sequences
        exclude_short_seq: if true, original sequences that are shorter than observation length+  max(TTE) are excluded.
                          This ensures that equal number of samples are extracted from each pedestrian sequence.
        risk_horizon: the risk horizon in terms of the number of frames in the future

    Returns:
        None
    """
    # Sample sequence within a range of TTE values
    print_msg(f'Generating data for {time_to_event[0]} to {time_to_event[1]} TTE')
    print_tracks_stats(_data, 'instances')
    assertion(pred_len <= min(time_to_event),
              f"Trajectory prediction length should be set <= min(TTE). pred_len({pred_len})>min_TTE({min(time_to_event)})")
    # Compute overlap sample count
    overlap_stride = obs_len if overlap == 0 else \
        int((1 - overlap) * obs_len)
    overlap_stride = 1 if overlap_stride < 1 else overlap_stride

    if time_to_event[0] > time_to_event[1]:
        time_to_event[0], time_to_event[1] = time_to_event[1], time_to_event[0]
    assert pred_len <= time_to_event[0], "Trajectory prediction length should be <= min(TTE)"
    # Initial estimate of start and end frames
    # Assumption is that predict_length does not exceed smaller TTE value
    start = obs_len + time_to_event[1]
    end = obs_len + time_to_event[0]
    sequence_length = obs_len + pred_len

    # Additional labels
    gen_tte_risk = True
    _adata = {'tte': [], 'risk_class': []}
    for k in _data:
        tracks = []
        samp_excluded = [0, 0]
        for e_idx, seq in enumerate(_data[k]):
            track = seq[:event_frames_idx[e_idx] + 1]
            # Excludes the track if it does not extend to the smaller TTE value
            if len(track) < obs_len + time_to_event[0]:
                samp_excluded[_data['activities'][e_idx][0][0]] += 1
                continue
            # if track is shorter than larger TTE value, exclude
            # This would allow uniform number of samples for each pedestrian instance
            # if not excluded, some pedestrian instances may have more tracks sampled from them
            if len(track) < obs_len + time_to_event[1]:
                if exclude_short_seq:
                    samp_excluded[_data['activities'][e_idx][0][0]] += 1
                    continue
                _start = 0
            else:
                _start = len(track) - start
            _end = len(track) - end + 1
            tracks.extend([track[i:i + sequence_length] for i in range(_start, _end, overlap_stride)])
            if gen_tte_risk:
                _adata['tte'].extend(
                    [[[len(track) - (i + obs_len)]] * sequence_length for i in range(_start, _end, overlap_stride)])
                _adata['risk_class'].extend([_data['bbox'][e_idx][i:i + obs_len + risk_horizon][-1] for i in
                                             range(_start, _end, overlap_stride)])
        _data[k] = tracks
        if gen_tte_risk:
            gen_tte_risk = False
    _data.update(_adata)
    # convert risk regions to classes
    convert_risk_classes(_data, img_dimension[0], **kwargs)
    print_msg(f"{samp_excluded} pedestrian instances excluded", 'default')
    print_2msg(f"Total number of samples:", f"{len(_data['bbox'])}")


# Label generation
def get_intention_labels(data_raw, opts):
    """
    Converts intention probabilities to classes
    Args:
        data_raw: raw data
        opts: data generation options

    Returns:
        Intention classes
    """
    int_labels = []
    num_int_class = opts.get('num_int_class', 3)
    for seq in data_raw['intention_prob']:
        for i in range(num_int_class):
            if (i < num_int_class - 1 and i * 1 / num_int_class <= seq[0][0] < (i + 1) * 1 / num_int_class) \
                    or i == num_int_class - 1:
                int_labels.append([[i]] * len(seq))
                break
    return int_labels


def convert_risk_classes(_data, img_width, num_risk_regions=12, **kwargs):
    """
    Converts the risk regions into classes according to the center of last bounding boxes
    Args:
        _data: dictionary of different sample types
        img_width: width of the image
        num_risk_regions: number of risk regions. The regions are symmetric, e.g. 0|1|2|2|1|0

    Returns:
        None
    """
    # Convert risk classes
    cel_n = num_risk_regions
    cel_w = img_width // (cel_n)

    for idx, seq in enumerate(_data['risk_class']):
        for i in range(num_risk_regions):
            if (i * cel_w <= (seq[0] + seq[2]) / 2 < (i + 1) * cel_w) or (i == num_risk_regions - 1):
                _data['risk_class'][idx] = [[i]] * len(_data['bbox'][idx])
                break

    cls_count = [0] * num_risk_regions
    for seq in _data['risk_class']:
        cls_count[seq[0][0]] += 1
    print_msg(f'Risk class, count', 'purple')
    print_msg("\t".join([str(i) for i in range(num_risk_regions)]), 'default')
    print_msg("\t".join([str(i) for i in cls_count]), 'default')


def add_grid_coordinates(_data, grid_resolution, img_dim, centers=None):
    """
    Creates grid coordinates. The image is divided into grids of a predefined size and coordinates
    are mapped to each grid. The mapping is done by finding the closest grid center to the center of
    a bounding box.
    Args:
        _data: data dictionary
        grid_resolution: the resolution in which grids are generated. With the current image dimensions
        the following grid resolutions are available: [1,2,3,4,5,6,8,10,12,15,20,24,30,40,60,120]
        img_dim: Image dimensions (width(x), height(y))
        centers: list of center coordinates. If None, they are grabbed from _data

    Returns:
        Number of grids. This is used for classification
    """
    assert img_dim[0] % grid_resolution == 0 and img_dim[1] % grid_resolution == 0, \
        "image dimension and grid resolution does not work"
    # [1,2,3,4,5,6,8,10,12,15,20,24,30,40,60,120]
    # img dimension (width, height) (x,y)
    num_grids_per_row = img_dim[0] // grid_resolution
    num_grids_per_column = img_dim[1] // grid_resolution
    grid_count = num_grids_per_row * num_grids_per_column
    print_2msg(f"number of grid points:", f"{grid_count}", 'purple')
    _data['grid_coord'] = []
    _data['grid_class'] = []
    # bbox (col(x1), row(y1), col(x2), row(y2))
    centers = _data['center'] if centers is None else centers
    for centers in centers:
        seq_grid = []
        seq_grid_class = []
        for c in centers:
            grid_x = int(round(c[0] / grid_resolution))
            grid_y = int(round(c[1] / grid_resolution))
            seq_grid.append([grid_x, grid_y])
            # Converting the grid coordinate to a single integer class
            seq_grid_class.append([grid_y * num_grids_per_row + grid_x])
        _data['grid_coord'].append(seq_grid)
        _data['grid_class'].append(seq_grid_class)
    return grid_count


def add_scaled_coordinates(_data, opts):
    """
    Adds scaled coordinates based on the area of the bounding boxes
    Args:
        _data: raw data
        opts: data generation options

    Returns:
        None
    """

    _opts = opts.get('scale_coord', {})
    b_areas = get_areas(_data, **_opts)
    if 'bbox_areas' in _data.keys():
        _data['bbox_areas'] = b_areas
    for dt in _data:
        if 'scaled' in dt:
            _data[dt] = np.array(_data[dt]) / np.expand_dims(b_areas, axis=-1)


def _get_norm_tracks(_data, opts):
    """
    Generates normalized coordinate points for data points containing bbox or center
    Args:
        _data: Data dictionary
        opts: options

    Returns:
        None
    """
    norm_idx = opts['obs_len'] - 1  # was original one
    for dt in _data:
        _data[dt] = np.array(_data[dt])
        if 'norm' in dt:
            _data[dt] = np.subtract(_data[dt], _data[dt][:, norm_idx:norm_idx + 1, :])


def _get_scales(data):
    """
    Computes the average scale for each given sequence
    Args:
        data: raw data

    Return:
        Array of scales
    """
    # 'bbox': list([x1, y1, x2, y2]) (float)  
    box_data = data['bbox']

    s_list = []
    for i, seq in enumerate(box_data):
        scale = np.mean(abs(np.array(seq)[:, 1] - np.array(seq)[:, 3]))
        s_list.append(scale)
    return np.array(s_list)


# Vehicle data
def get_vehicle_dtypes(vehicle_data, opts):
    """
    Generates vehicle data. For PIE, it is [speed,  yaw, roll, pitch].
    In the case of JAAD, it sends back driver behavior data instead
    Args:
        vehicle_data: vehicle data
        opts: data generation options

    Returns:
        List of vehicle data
    """
    yrp_str = ['yaw', 'roll', 'pitch']
    gyro_str = ['gyroX', 'gyroY', 'gyroZ']
    acc_str = ['accX', 'accY', 'accZ']
    veh_data = []
    for _dt in vehicle_data['types']:
        dtype = None
        dt = _dt.split('norm_')[1] if 'norm' in _dt else _dt
        if 'speed' in dt:
            dtype = ['obd_speed']
        elif dt in yrp_str:
            dtype = ['yrp']
        elif dt in gyro_str:
            dtype = ['gyro']
        elif dt in acc_str:
            dtype = ['acc']
        elif dt == 'coord':
            dtype = ['gps_coord']
        elif dt == 'h_angle':
            dtype = ['heading_angle']
        elif 'vehicle_act' in dt:
            dtype = ['vehicle_act']
        else:
            raise Exception(f"{dt} is wrong vehicle data type for dataset {opts['dataset'].lower()}")
        veh_data.extend(dtype)
    return list(set(veh_data))


def _get_vehicle_dtypes(vehicle_data, data_raw):
    """
    Generates vehicle data. For PIE, it is [speed,  yaw, roll, pitch].
    In the case of JAAD sends back driver behavior data instead. This is an auxiliary function that can be potentially
    used for visualization purposes.
    Args:
        vehicle_data: vehicle data
        data_raw: raw data

    Returns:
        List of vehicle data
    """
    yrp_str = ['yaw', 'roll', 'pitch']
    gyro_str = ['gyroX', 'gyroY', 'gyroZ']
    acc_str = ['accX', 'accY', 'accZ']
    veh_data = []
    for _dt in vehicle_data['types']:
        if 'norm' in _dt:
            dt = _dt.split('norm_')[1]
        else:
            dt = _dt
        if 'speed' in dt:
            if 'obd_speed' not in data_raw:
                msg_str = 'Jaad dataset does not have vehicle information\n' + \
                          'Vehicle actions are used instead'
                print_msg(msg_str, 'yellow')
                return ['vehicle_act']
            else:
                dtype = ['obd_speed']
        elif dt in yrp_str:
            dtype = ['yrp']
        elif dt in gyro_str:
            dtype = ['gyro']
        elif dt in acc_str:
            dtype = ['acc']
        elif dt == 'coord':
            dtype = ['gps_coord']
        elif dt == 'h_angle':
            dtype = ['heading_angle']
        else:
            raise Exception(f"{dt} is wrong vehicle data type")
        veh_data.extend(dtype)
    return list(set(veh_data))


# Filter utilities
def apply_filter_vehicle_data(_data, data_type, opts):
    """
    Applies a filter to vehicle data for smoothing
    Args:
        _data: data
        data_type: type of data (train/test/val) mainly for storing
        opts: data generation options

    Returns:
        None
    """
    filter_type = opts['vehicle_data'].get('filter_type')
    if filter_type is None:
        return
    assert filter_type in ['low_pass', 'median']
    if opts['sequence_type'] == 'intention':
        aux = 'intent'
    else:
        aux = f"_{opts['time_to_event'][0]}-{opts['time_to_event'][1]}" if isinstance(opts['time_to_event'], list) \
                                                                           and len(opts['time_to_event']) == 2 else ""
    save_path = f"{data_type}_{len(_data['bbox'])}{aux}_{filter_type}"
    if filter_type == 'median':
        median_filter(_data, opts['vehicle_data'].get('sensors', []),
                      keep_same=True,
                      save_path=save_path,
                      root_path=opts['vehicle_data'].get('root_path', 'filter_data'),
                      **opts['vehicle_data'].get('median_filter'))
    else:
        low_pass_filter(_data, opts['vehicle_data'].get('sensors', []),
                        keep_same=True,
                        save_path=save_path,
                        root_path=opts['vehicle_data'].get('root_path', 'filter_data'),
                        **opts['vehicle_data'].get('low_pass_filter'))


def low_pass_filter(data, dtypes=None,
                    order=4, freq=5, fs=30,
                    root_path='filter_data',
                    save_path='low_pass',
                    override=False,
                    keep_same=False):
    """
    Applies low pass filter to vehicle data
    Args:
        data: data
        dtypes: data types to apply filter to
        order: order of the filter
        freq: frequency of the filter
        fs: sampling frequency of the filter
        root_path: root folder for saving the file
        save_path: file name to save as
        override: whether to override the original file
        keep_same: whether to modify the label id in the data dictionary

    Returns:
        None
    """
    dtypes = dtypes or ['acc', 'gyro']
    dtypes = [dtypes] if not isinstance(dtypes, list) else dtypes
    for dtype in dtypes:
        if dtype not in data:
            continue
        _save_path = f"{save_path}_{dtype}_{order}_{freq}_{fs}.pkl"
        file_path = os.path.join(root_path, _save_path)
        os.makedirs(root_path, exist_ok=True)
        if os.path.exists(file_path) and not override:
            _d = read_pickle(file_path)
        else:
            _d = np.array(data[dtype])
            b_filt, a_filt = signal.butter(order, freq, 'low', fs=fs)
            # This is to handle the padding in filtering which requires that the
            # size of signal <= pad length(default is 3*max(len(b_filt), len(a_filt))).
            # if set to None default is used otherwise it is reduced by 1 below the signal length
            if _d.shape[1] <= 3*max(len(b_filt), len(a_filt)):
                padlen = _d.shape[1] - 1
            else:
                padlen = None # use default
            _d = signal.filtfilt(b_filt, a_filt, _d, axis=1,  padlen=padlen)
            with open(file_path, 'wb') as fid:
                pickle.dump(_d, fid, pickle.HIGHEST_PROTOCOL)
        dt_id = dtype if keep_same else f"lpf{dtype}"
        data[dt_id] = _d


def median_filter(data, dtypes=None, kernel_size=5,
                  root_path='filter_data',
                  save_path='median',
                  override=False,
                  keep_same=False):
    """
    Applies a median filter to vehicle sensor readings
    Args:
        data: data
        dtypes: type of the data to apply the filter to
        kernel_size: kernel size of the filter
        root_path: folder to save the output
        save_path: name of the file to save to
        override: whether to override  the saved file
        keep_same: whether to keep the data label the same

    Returns:
        None
    """
    dtypes = dtypes or ['acc', 'gyro']
    dtypes = [dtypes] if not isinstance(dtypes, list) else dtypes

    for dtype in dtypes:
        if dtype not in data:
            continue
        save_path = f"{save_path}_{dtype}_{kernel_size}.pkl"
        file_path = os.path.join(root_path, save_path)
        if os.path.exists(file_path) and not override:
            _d = read_pickle(file_path)
        else:
            _d = np.array(data[dtype])
            _d = signal.medfilt(_d, kernel_size)
            with open(file_path, 'wb') as fid:
                pickle.dump(_d, fid, pickle.HIGHEST_PROTOCOL)
        dt_id = dtype if keep_same else f"mf{dtype}"
        data[dt_id] = _d


# Others
def get_data_types(opts):
    """
    Returns the data types for data generation
    Args:
        opts: data generation options

    Returns:
        Set of all data types
    """
    if opts['data_types'] == 'default':
        dtypes = ['bbox', 'scaled_bbox', 'actions', 'looks',
                  'activities', 'risk_class', 'tte']
        if opts['dataset'].lower() == 'pie':
            dtypes += ['speed', 'yrp', 'signalized', 'traffic', 'acc', 'gps_coord']
    else:
        dtypes = opts['data_types']
        # For JAAD 'vehicle_act' can be used instead of speed
    return set(dtypes + opts['obs_input_type'] +
               opts['pred_output_type'] +
               opts['dec_input_type'] +
               ['image', 'pid'])


def denorm_track(_track, org_track, opts):
    """
    Denormalizes the output trajectories of the model
    Args:
        _track: array of tracks
        org_track: array of original tracks
        opts: data generation options

    Returns:
        List of henerated tracks
    """
    track = copy.deepcopy(_track)
    track = np.add(track, org_track[opts['observe_length'] - 1])
    track = track.tolist()
    return track
